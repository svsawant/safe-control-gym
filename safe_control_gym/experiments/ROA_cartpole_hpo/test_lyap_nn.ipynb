{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from safe_control_gym.experiments.ROA_cartpole.utilities import *\n",
    "from lyapnov import LyapunovNN, Lyapunov, QuadraticFunction, GridWorld_pendulum\n",
    "from utilities import balanced_class_weights, dlqr, \\\n",
    "                      get_discrete_linear_system_matrices, onestep_dynamics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NN to fit the Lyapnov function defined by LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize) # np print full array\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class Options(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Options, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "OPTIONS = Options(np_dtype              = np.float32,\n",
    "                  torch_dtype           = torch.float32,\n",
    "                  eps                   = 1e-8,                            # numerical tolerance\n",
    "                  saturate              = True,                            # apply saturation constraints to the control input\n",
    "                  use_zero_threshold    = True,                            # assume the discretization is infinitely fine (i.e., tau = 0)\n",
    "                  pre_train             = True,                            # pre-train the neural network to match a given candidate in a supervised approach\n",
    "                  dpi                   = 150,\n",
    "                  num_cores             = 4,\n",
    "                  num_sockets           = 1,\n",
    "                #   tf_checkpoint_path    = \"./tmp/lyapunov_function_learning.ckpt\"\n",
    "                )\n",
    "\n",
    "# detect torch device\n",
    "myDevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myDevice = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Constants ####################################\n",
    "dt = 0.01   # sampling time\n",
    "g = 9.81    # gravity\n",
    "\n",
    "# True system parameters\n",
    "m = 0.15    # pendulum mass\n",
    "L = 0.5     # pole length\n",
    "b = 0.1     # rotational friction\n",
    "\n",
    "# State and action normalizers\n",
    "theta_max = np.deg2rad(180)                     # angular position [rad]\n",
    "omega_max = np.deg2rad(360)                     # angular velocity [rad/s]\n",
    "# u_max     = g * m * L * np.sin(np.deg2rad(60))  # torque [N.m], control action\n",
    "u_max = 0.5\n",
    "\n",
    "state_norm = (theta_max, omega_max)\n",
    "action_norm = (u_max,)\n",
    "\n",
    "# Dimensions and domains\n",
    "state_dim     = 2\n",
    "action_dim    = 1\n",
    "state_limits  = np.array([[-1., 1.]] * state_dim)\n",
    "action_limits = np.array([[-1., 1.]] * action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### System dynamics ################################\n",
    "# Initialize system class and its linearization\n",
    "pendulum = InvertedPendulum(m, L, b, dt, [state_norm, action_norm])\n",
    "A, B = pendulum.linearize()\n",
    "# print(\"A\\n \", A)\n",
    "# print(\"B\\n \", B)\n",
    "# dynamics = pendulum.__call__\n",
    "dynamics = pendulum.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 10000\n",
      "Discretization constant (tau): 0.0\n"
     ]
    }
   ],
   "source": [
    "############################### Discretization ################################\n",
    "state_constraints = np.array([[-theta_max, theta_max], [-omega_max, omega_max]])\n",
    "# print('state_constraints: ', state_constraints)\n",
    "num_states = 100\n",
    "\n",
    "grid_limits = np.array([[-1., 1.], ] * state_dim)\n",
    "# state_discretization = gridding(state_dim, state_constraints=None, num_states = 100)\n",
    "state_discretization = GridWorld_pendulum(grid_limits, num_states)\n",
    "# state_discretization = gridding(state_dim, state_constraints, num_states = 100)\n",
    "# print('state_discretization.all_points.shape: ', state_discretization.all_points.shape)\n",
    "\n",
    "# Discretization constant\n",
    "if OPTIONS.use_zero_threshold:\n",
    "    tau = 0.0\n",
    "else:\n",
    "    tau = np.sum(state_discretization.unit_maxes) / 2\n",
    "\n",
    "print('Grid size: {}'.format(state_discretization.nindex))\n",
    "print('Discretization constant (tau): {}'.format(tau))\n",
    "\n",
    "# Set initial safe set as a ball around the origin (in normalized coordinates)\n",
    "cutoff_radius    = 0.1\n",
    "initial_safe_set = np.linalg.norm(state_discretization.all_points, ord=2, axis=1) <= cutoff_radius\n",
    "# print('state_discretization.all_points.shape: ', state_discretization.all_points.shape)\n",
    "# print('initial_safe_set.sum(): ', initial_safe_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## define LQR policy ##############################\n",
    "Q = np.identity(state_dim).astype(OPTIONS.np_dtype)     # state cost matrix\n",
    "Q = np.diag([5, 1])\n",
    "R = 1* np.identity(action_dim).astype(OPTIONS.np_dtype)    # action cost matrix\n",
    "K, P_lqr = dlqr(A, B, Q, R) \n",
    "\n",
    "policy = lambda x: -K @ x\n",
    "if OPTIONS.saturate:\n",
    "    policy = lambda x: np.clip(-K @ x, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############  closed-loop dynamics and Lipschitz constants ##############\n",
    "    \n",
    "cl_dynamics = lambda x: dynamics(np.concatenate([x, policy(x)]))\n",
    "L_pol = lambda x: np.linalg.norm(-K, 1)\n",
    "L_dyn = lambda x: np.linalg.norm(A, 1) + np.linalg.norm(B, 1) * L_pol(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyapunov_lqr.safe_set.sum()\n",
      " 2006\n"
     ]
    }
   ],
   "source": [
    "########################## define Lyapunov LQR ##########################\n",
    "lyapunov_function = QuadraticFunction(P_lqr)\n",
    "# Approximate local Lipschitz constants with gradients\n",
    "grad_lyapunov_function = lambda x: 2 * torch.tensor(P_lqr, dtype=torch.float32) @ x\n",
    "L_v = lambda x: torch.norm(grad_lyapunov_function(x), p=1, dim=-1, keepdim=True)\n",
    "# Initialize Lyapunov class\n",
    "lyapunov_lqr = Lyapunov(state_discretization, lyapunov_function, cl_dynamics, L_dyn, L_v, tau, policy, initial_safe_set)\n",
    "lyapunov_lqr.update_values()\n",
    "lyapunov_lqr.update_safe_set()\n",
    "# print('lyapunov_lqr.c_max\\n', lyapunov_lqr.c_max)\n",
    "print('lyapunov_lqr.safe_set.sum()\\n', lyapunov_lqr.safe_set.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn\n",
      " LyapunovNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): Linear(in_features=2, out_features=62, bias=False)\n",
      "    (2): Linear(in_features=64, out_features=33, bias=False)\n",
      "    (3): Linear(in_features=64, out_features=33, bias=False)\n",
      "  )\n",
      ")\n",
      "layers.0.weight torch.Size([2, 2])\n",
      "layers.1.weight torch.Size([62, 2])\n",
      "layers.2.weight torch.Size([33, 64])\n",
      "layers.3.weight torch.Size([33, 64])\n"
     ]
    }
   ],
   "source": [
    "######################## define Lyapunov NN ########################\n",
    "# initialize Lyapunov NN\n",
    "layer_dim = [64, 64, 64]\n",
    "# layer_dim = [128, 128, 128]\n",
    "activations = [torch.nn.Tanh(), torch.nn.Tanh(), torch.nn.Tanh()]\n",
    "nn = LyapunovNN(state_dim, layer_dim, activations)\n",
    "print('nn\\n', nn)\n",
    "for name, param in nn.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "\n",
    "# approximate local Lipschitz constant with gradient\n",
    "grad_lyapunov_function = \\\n",
    "    lambda x: torch.autograd.grad(nn(x), x, \\\n",
    "                    torch.ones_like(nn(x)), allow_unused=True,)[0]\n",
    "lyapunov_nn = Lyapunov(state_discretization, nn, \\\n",
    "                          cl_dynamics, L_dyn, L_v, tau, policy, \\\n",
    "                          initial_safe_set)\n",
    "lyapunov_nn.update_values()\n",
    "lyapunov_nn.update_safe_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe_set_fraction [0.0118]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################\n",
    "# train the parameteric Lyapunov candidate in order to expand the verifiable\n",
    "# safe set toward the brute-force safe set\n",
    "test_classfier_loss = []\n",
    "test_decrease_loss   = []\n",
    "roa_estimate         = np.copy(lyapunov_nn.safe_set)\n",
    "roa = np.copy(lyapunov_lqr.safe_set) # train the nn to fit the lqr roa\n",
    "\n",
    "# grid              = lyapunov_lqr.discretization\n",
    "grid              = lyapunov_nn.discretization\n",
    "c_max             = [lyapunov_nn.c_max, ]\n",
    "safe_set_fraction = [lyapunov_nn.safe_set.sum() / grid.nindex, ]\n",
    "print('safe_set_fraction', safe_set_fraction)\n",
    "roa_estimate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight torch.Size([2, 2])\n",
      "layers.1.weight torch.Size([62, 2])\n",
      "layers.2.weight torch.Size([33, 64])\n",
      "layers.3.weight torch.Size([33, 64])\n"
     ]
    }
   ],
   "source": [
    "######################### traning hyperparameters #######################\n",
    "outer_iters = 5\n",
    "inner_iters = 10\n",
    "horizon     = 100\n",
    "test_size   = int(1e4)\n",
    "\n",
    "safe_level = 1\n",
    "lagrange_multiplier = 5000\n",
    "level_multiplier = 1.3\n",
    "learning_rate = 5e-3\n",
    "batch_size    = int(1e3)\n",
    "\n",
    "optimizer = torch.optim.SGD(lyapunov_nn.lyapunov_function.parameters(), lr=learning_rate)\n",
    "# print('optimizer\\n', optimizer)\n",
    "for name, param in lyapunov_nn.lyapunov_function.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomize 10 initial conditions and feed them into the neural network\n",
    "batch_size = 10\n",
    "x0 = torch.rand(batch_size, state_dim, dtype=OPTIONS.torch_dtype)\n",
    "x0\n",
    "x0.reshape(batch_size, -1, state_dim)\n",
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2 and 10x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# feed the initial conditions into the neural network and get the output\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y0 \u001b[39m=\u001b[39m lyapunov_nn\u001b[39m.\u001b[39;49mlyapunov_function(x0)\n\u001b[1;32m      3\u001b[0m y0\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/safe/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repositories/scg_mx/safe_control_gym/experiments/ROA_cartpole/lyapnov.py:423\u001b[0m, in \u001b[0;36mLyapunovNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    421\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(x)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    422\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m--> 423\u001b[0m     layer_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel[i], x)\n\u001b[1;32m    424\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivations[i](layer_output)\n\u001b[1;32m    425\u001b[0m values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39msquare(x), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2 and 10x2)"
     ]
    }
   ],
   "source": [
    "# feed the initial conditions into the neural network and get the output\n",
    "y0 = lyapunov_nn.lyapunov_function(x0)\n",
    "y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8068, -0.7251],\n",
       "        [-0.7214,  0.6148],\n",
       "        [-0.2046, -0.6693],\n",
       "        [ 0.8550, -0.3045],\n",
       "        [ 0.5016,  0.4520],\n",
       "        [ 0.7666,  0.2473],\n",
       "        [ 0.5019, -0.3022],\n",
       "        [-0.4601,  0.7918],\n",
       "        [-0.1438,  0.9297],\n",
       "        [ 0.3269,  0.2434]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
